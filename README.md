# Prompt-Learning
Collect recent papers on prompt learning

core thinking
+ When and why CLIP-prior works well?

## Towards vision-language prompt
|  Title   | Year  | Venue | Code |
|  ----  | ----  | ---- | ---- |
| [Unsupervised Prompt Learning for Vision-Language Models](https://arxiv.org/pdf/2204.03649.pdf) | 2022 | Arxiv | [Link](https://github.com/tonyhuang2022/UPL)|
| [Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language Modeling](https://arxiv.org/abs/2111.03930) | 2022 | Arxiv | [Link](https://github.com/gaopengcuhk/Tip-Adapter)|
| [CLIP-Adapter: Better Vision-Language Models with Feature Adapters](https://arxiv.org/pdf/2110.04544.pdf) | 2022 | Arxiv | [Link](https://github.com/gaopengcuhk/CLIP-Adapter)|
| [Conditional Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2203.05557) | 2022 | CVPR | [Link](https://github.com/KaiyangZhou/CoOp)|
| [Learning to Prompt for Vision-Language Models](https://arxiv.org/abs/2109.01134) | 2021 | Arxiv | [Link](https://github.com/KaiyangZhou/CoOp)|
| [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/pdf/2103.00020.pdf) | 2021 | Arxiv | [Link](https://github.com/OpenAI/CLIP)|
| [Neural Discrete Representation Learning](https://arxiv.org/abs/1711.00937) | 2017 | Arxiv | [Link](https://github.com/zalandoresearch/pytorch-vq-vae)|


## Towards application
|  Title   | Year  | Venue | Code |
|  ----  | ----  | ---- | ---- |
| [Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model](https://arxiv.org/pdf/2203.14940.pdf) | 2022 | CVPR | [Link](https://github.com/dyabel/detpro)|
| [Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos](https://arxiv.org/pdf/2203.14104.pdf) | 2022 | CVPR | [Link](https://github.com/ttlmh/Bridge-Prompt)|


